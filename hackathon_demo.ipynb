{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load bible data and create a dataframe from the pkl\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_pickle('bible_df.pkl')\n",
    "# Print out the column names\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the bible into Chroma - use the default embeddings\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "# Create a client, and create a collection\n",
    "collection_name = 'the_bible'\n",
    "persist_directory = 'chroma'\n",
    "\n",
    "client = chromadb.Client(Settings(persist_directory=persist_directory, chroma_db_impl=\"duckdb+parquet\"))\n",
    "collection = client.create_collection(collection_name)\n",
    "\n",
    "# Add the bible to the collection - Chroma will embed it for you\n",
    "\n",
    "chapters = df['Chapter'].tolist()\n",
    "books = df['Book Name'].tolist()\n",
    "verses = df['Verse'].tolist()\n",
    "\n",
    "collection.add(\n",
    "    ids = [str(id) for id in df['Verse ID'].tolist()],\n",
    "    embeddings=df['Embedding'].tolist(),\n",
    "    documents=df['Text'].tolist(),\n",
    "    metadatas=[{\"chapter\": chapter, \"book\": book, \"verse\": verse} for chapter, book, verse in zip(chapters, books, verses)]\n",
    ")\n",
    "\n",
    "client.persist()\n",
    "del client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = collection.get()\n",
    "\n",
    "embeddings = items['embeddings']\n",
    "books = [metadata['book'] for metadata in items['metadatas']]\n",
    "\n",
    "print(len(embeddings))\n",
    "del collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project the bible embeddings to 2D using UMAP\n",
    "import umap\n",
    "import umap.plot\n",
    "\n",
    "mapper = umap.UMAP().fit(embeddings)\n",
    "\n",
    "umap.plot.points(mapper, labels=np.array(books), background='black', show_legend=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.vectorstores'; 'langchain' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Let's ask God some questions\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvectorstores\u001b[39;00m \u001b[39mimport\u001b[39;00m Chroma\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchains\u001b[39;00m \u001b[39mimport\u001b[39;00m VectorDBQAWithSourcesChain\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m \u001b[39mimport\u001b[39;00m OpenAI\n",
      "File \u001b[0;32m~/Projects/chroma/langchain.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Let's ask God some questions\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvectorstores\u001b[39;00m \u001b[39mimport\u001b[39;00m Chroma\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchains\u001b[39;00m \u001b[39mimport\u001b[39;00m VectorDBQAWithSourcesChain\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m \u001b[39mimport\u001b[39;00m OpenAI\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain.vectorstores'; 'langchain' is not a package"
     ]
    }
   ],
   "source": [
    "# Let's ask God some questions\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import VectorDBQAWithSourcesChain\n",
    "from langchain import OpenAI\n",
    "\n",
    "collection_name = 'the_bible'\n",
    "persist_directory = 'chroma'\n",
    "\n",
    "# Read in the oepnai api key from openai.key\n",
    "openai_api_key = open('openai.key', 'r').read()\n",
    "\n",
    "docsearch = Chroma(collection_name=collection_name, persist_directory=persist_directory)\n",
    "chain = VectorDBQAWithSourcesChain.from_chain_type(OpenAI(temperature=0, openai_api_key=openai_api_key), chain_type=\"stuff\", vectorstore=docsearch)\n",
    "\n",
    "chain({\"question\": \"What is the greatest good?\"}, return_only_outputs=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chroma-langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c909e91d0cd7642213937968dfc91c71973575965f56cdcabb1e0b29abe5f7fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
